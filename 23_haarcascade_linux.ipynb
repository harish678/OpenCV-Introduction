{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "haarcascade_linux.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "fbzRDo2DOgMV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***STEPS:***\n",
        "\n",
        "1. Collect \"Negative\" or \"Background images\"\n",
        "      - Any image without the object (we need), thousands of them.\n",
        "\n",
        "2. Collect or create \"Positive\" images\n",
        "      - Thousands of images of the object.\n",
        "\n",
        "3. Create a positive vector file by stitching all the positives.\n",
        "      - Done with OpenCV command.\n",
        "\n",
        "4. Train Cascade\n",
        "      - Done with OpenCV command."
      ]
    },
    {
      "metadata": {
        "id": "W_uh5nQ7QHsG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Negative Images:** bg.txt file contains path to each image, by line.\n",
        "\n",
        "ex: neg/1.jpg\n",
        "\n",
        "**Positive Images:** pos.txt contains path to each image, along with how many objects, and where they are located\n",
        "\n",
        "ex: pos/1.jpg 1 0 0 50 50  => image, no of objs, rectange coordinates."
      ]
    },
    {
      "metadata": {
        "id": "zhCMCBtsQ-TO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "negative images > positive images.\n",
        "\n",
        "Try small images. 100 x 100 -> negatives, 50 x 50 -> positives.\n",
        "\n",
        "For trainig we use even smaller images (20 x 20).\n",
        "\n",
        "Have ~ double positive images compared to negative images."
      ]
    },
    {
      "metadata": {
        "id": "LcrrefPaOVW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir opencv_workspace\n",
        "import os\n",
        "os.chdir('opencv_workspace/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j-A62wW_R5CE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "0ec56140-0c78-4bdb-c522-c753059bab2f"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Itseez/opencv.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'opencv'...\n",
            "remote: Enumerating objects: 2, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 251159 (delta 0), reused 0 (delta 0), pack-reused 251157\u001b[K\n",
            "Receiving objects: 100% (251159/251159), 457.09 MiB | 25.78 MiB/s, done.\n",
            "Resolving deltas: 100% (175181/175181), done.\n",
            "Checking out files: 100% (5801/5801), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MlM3Gql6SzdB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download images by link\n",
        "import urllib.request\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def store_raw_images():\n",
        "  neg_images_link = 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n00523513'\n",
        "  neg_image_urls = urllib.request.urlopen(neg_images_link).read().decode()\n",
        "  pic_num = 1\n",
        "\n",
        "  if not os.path.exists('neg'):\n",
        "     os.makedirs('neg')\n",
        "     \n",
        "  for i in neg_image_urls.split('\\n'):\n",
        "      try:\n",
        "        urllib.request.urlretrieve(i,\"neg/\"+str(pic_num)+'.jpg')\n",
        "        img = cv2.imread(\"neg/\"+str(pic_num)+'.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "        resized_image = cv2.resize(img, (100, 100))\n",
        "        cv2.imwrite(\"neg/\"+str(pic_num)+\".jpg\",resized_image)\n",
        "        pic_num += 1\n",
        "      except Exception as e:\n",
        "        (str(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3sZhr8BNVKOt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "store_raw_images()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fBBPHkfoVCAZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# copy the unecessary image pattern in the uglies folder and run the script\n",
        "def find_uglies():\n",
        "    match = False\n",
        "    for file_type in ['neg']:\n",
        "        for img in os.listdir(file_type):\n",
        "            for ugly in os.listdir('uglies'):\n",
        "                try:\n",
        "                    current_image_path = str(file_type)+'/'+str(img)\n",
        "                    ugly = cv2.imread('uglies/'+str(ugly))\n",
        "                    question = cv2.imread(current_image_path)\n",
        "                    if ugly.shape == question.shape and not(np.bitwise_xor(ugly,question).any()):\n",
        "                        print('That is one ugly pic! Deleting!')\n",
        "                        print(current_image_path)\n",
        "                        os.remove(current_image_path)\n",
        "                except Exception as e:\n",
        "                    print(str(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N9o0zporYWfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create the descriptor files\n",
        "def create_pos_n_neg():\n",
        "    for file_type in ['neg']:\n",
        "        \n",
        "        for img in os.listdir(file_type):\n",
        "\n",
        "            if file_type == 'pos':\n",
        "                line = file_type+'/'+img+' 1 0 0 50 50\\n'\n",
        "                with open('info.dat','a') as f:\n",
        "                    f.write(line)\n",
        "            elif file_type == 'neg':\n",
        "                line = file_type+'/'+img+'\\n'\n",
        "                with open('bg.txt','a') as f:\n",
        "                    f.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bepRcJR9ZHON",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pos images in info and data for cascade information\n",
        "!mkdir data info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dAVjPByjZR6I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We're ready to create some positive samples now, based on the watch5050.jpg image. To do this, run the following via the terminal, while in the workspace:\n",
        "opencv_createsamples -img watch5050.jpg -bg bg.txt -info info/info.lst -pngoutput info -maxxangle 0.5 -maxyangle 0.5 -maxzangle 0.5 -num 1950"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dezFcHZQZZKb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create the vector file, which is basically where we stitch all of our positive images together\n",
        "\n",
        "opencv_createsamples -info info/info.lst -num 1950 -w 20 -h 20 -vec positives.vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0B1RcDO4aKdj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nohup opencv_traincascade -data data -vec positives.vec -bg bg.txt -numPos 1800 -numNeg 900 -numStages 10 -w 20 -h 20 &"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7LERNEnclgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "#this is the cascade we just made. Call what you want\n",
        "watch_cascade = cv2.CascadeClassifier('watchcascade10stage.xml')\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while 1:\n",
        "    ret, img = cap.read()\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    \n",
        "    # add this\n",
        "    # image, reject levels level weights.\n",
        "    watches = watch_cascade.detectMultiScale(gray, 50, 50)\n",
        "    \n",
        "    # add this\n",
        "    for (x,y,w,h) in watches:\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        cv2.putText(img,'Watch',(x-w,y-h), font, 0.5, (11,255,255), 2, cv2.LINE_AA)\n",
        "        #cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
        "\n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "\n",
        "        \n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        roi_color = img[y:y+h, x:x+w]\n",
        "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "        for (ex,ey,ew,eh) in eyes:\n",
        "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "\n",
        "    cv2.imshow('img',img)\n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VprMqdjmaifs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}